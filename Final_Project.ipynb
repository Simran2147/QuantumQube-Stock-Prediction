{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91487f2d",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "415be5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# For data maniplution\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for dataset handling and MAE\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import FunctionTransformer, RobustScaler\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# importing models for training and testing\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import *\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d9bfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset to dataframe\n",
    "data_train = pd.read_csv('train.csv').drop(['row_id', 'time_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset to dataframe\n",
    "data_test = pd.read_csv('test.csv').drop(['row_id', 'time_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the first 10 rows\n",
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936ea00",
   "metadata": {},
   "source": [
    "###Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting information about the train data\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1bd4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting descriptive statistics about the train data\n",
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data: number of rows and columns\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the heatmap for the train dataset\n",
    "plt.figure(figsize=(16,16))\n",
    "sns.heatmap(data_train.corr(),annot=True,cmap='crest')\n",
    "plt.title('Heatmap of the train dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the time series data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_train['target'], label='Target')\n",
    "plt.title('Time Series Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>13552875.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>1962.72</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>5647.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.779432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969969.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000115</td>\n",
       "      <td>3647503.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>6663.16</td>\n",
       "      <td>1.000283</td>\n",
       "      <td>3810.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.499819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9412959.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>21261245.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>5139.20</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>2570.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.959801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2394875.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>9473209.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>52011.60</td>\n",
       "      <td>1.000041</td>\n",
       "      <td>2169.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3039700.65</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000969</td>\n",
       "      <td>6248958.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>6191.00</td>\n",
       "      <td>1.000646</td>\n",
       "      <td>6199.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.970333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "5         5        0                  0            0.00   \n",
       "6         6        0                  0       969969.40   \n",
       "7         7        0                  0      9412959.10   \n",
       "8         8        0                  0      2394875.85   \n",
       "9         9        0                  0      3039700.65   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        0.0   \n",
       "1                       -1         0.999896    1642214.25        0.0   \n",
       "2                       -1         0.999561    1819368.03        0.0   \n",
       "3                       -1         1.000171   18389745.62        0.0   \n",
       "4                       -1         0.999532   17860614.95        0.0   \n",
       "5                        0         1.000635   13552875.92        0.0   \n",
       "6                        1         1.000115    3647503.98        0.0   \n",
       "7                        1         0.999818   21261245.87        0.0   \n",
       "8                        1         0.999916    9473209.08        0.0   \n",
       "9                       -1         1.000969    6248958.45        0.0   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \n",
       "0         0.0   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704  \n",
       "1         0.0   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986  \n",
       "2         0.0   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950  \n",
       "3         0.0   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200  \n",
       "4         0.0   0.999394  16485.54   1.000016     434.10  1.0 -7.349849  \n",
       "5         0.0   0.999779   1962.72   1.000635    5647.65  1.0  6.779432  \n",
       "6         0.0   0.999506   6663.16   1.000283    3810.48  1.0 -2.499819  \n",
       "7         0.0   0.999741   5139.20   1.000130    2570.60  1.0 -1.959801  \n",
       "8         0.0   0.999022  52011.60   1.000041    2169.36  1.0 -5.970001  \n",
       "9         0.0   0.999354   6191.00   1.000646    6199.00  1.0  7.970333  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new dataframe with null values replaced by 0\n",
    "train_df_0 = data_train.copy()\n",
    "train_df_0.fillna(0, inplace=True)\n",
    "train_df_0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>13552875.92</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>1962.72</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>5647.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.779432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969969.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000115</td>\n",
       "      <td>3647503.98</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>6663.16</td>\n",
       "      <td>1.000283</td>\n",
       "      <td>3810.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.499819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9412959.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>21261245.87</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>5139.20</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>2570.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.959801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2394875.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>9473209.08</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>52011.60</td>\n",
       "      <td>1.000041</td>\n",
       "      <td>2169.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3039700.65</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000969</td>\n",
       "      <td>6248958.45</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>6191.00</td>\n",
       "      <td>1.000646</td>\n",
       "      <td>6199.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.970333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "5         5        0                  0            0.00   \n",
       "6         6        0                  0       969969.40   \n",
       "7         7        0                  0      9412959.10   \n",
       "8         8        0                  0      2394875.85   \n",
       "9         9        0                  0      3039700.65   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64   1.001713   \n",
       "1                       -1         0.999896    1642214.25   1.001713   \n",
       "2                       -1         0.999561    1819368.03   1.001713   \n",
       "3                       -1         1.000171   18389745.62   1.001713   \n",
       "4                       -1         0.999532   17860614.95   1.001713   \n",
       "5                        0         1.000635   13552875.92   1.001713   \n",
       "6                        1         1.000115    3647503.98   1.001713   \n",
       "7                        1         0.999818   21261245.87   1.001713   \n",
       "8                        1         0.999916    9473209.08   1.001713   \n",
       "9                       -1         1.000969    6248958.45   1.001713   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \n",
       "0     0.99966   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704  \n",
       "1     0.99966   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986  \n",
       "2     0.99966   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950  \n",
       "3     0.99966   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200  \n",
       "4     0.99966   0.999394  16485.54   1.000016     434.10  1.0 -7.349849  \n",
       "5     0.99966   0.999779   1962.72   1.000635    5647.65  1.0  6.779432  \n",
       "6     0.99966   0.999506   6663.16   1.000283    3810.48  1.0 -2.499819  \n",
       "7     0.99966   0.999741   5139.20   1.000130    2570.60  1.0 -1.959801  \n",
       "8     0.99966   0.999022  52011.60   1.000041    2169.36  1.0 -5.970001  \n",
       "9     0.99966   0.999354   6191.00   1.000646    6199.00  1.0  7.970333  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new dataframe with null values replaced by mean\n",
    "train_df_mean = data_train.copy()\n",
    "train_df_mean.fillna(train_df_mean.mean(), inplace=True)\n",
    "train_df_mean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>13552875.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>1962.72</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>5647.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.779432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969969.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000115</td>\n",
       "      <td>3647503.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>6663.16</td>\n",
       "      <td>1.000283</td>\n",
       "      <td>3810.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.499819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9412959.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>21261245.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>5139.20</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>2570.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.959801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2394875.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>9473209.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>52011.60</td>\n",
       "      <td>1.000041</td>\n",
       "      <td>2169.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3039700.65</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000969</td>\n",
       "      <td>6248958.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>6191.00</td>\n",
       "      <td>1.000646</td>\n",
       "      <td>6199.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.970333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "5         5        0                  0            0.00   \n",
       "6         6        0                  0       969969.40   \n",
       "7         7        0                  0      9412959.10   \n",
       "8         8        0                  0      2394875.85   \n",
       "9         9        0                  0      3039700.65   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        1.0   \n",
       "1                       -1         0.999896    1642214.25        1.0   \n",
       "2                       -1         0.999561    1819368.03        1.0   \n",
       "3                       -1         1.000171   18389745.62        1.0   \n",
       "4                       -1         0.999532   17860614.95        1.0   \n",
       "5                        0         1.000635   13552875.92        1.0   \n",
       "6                        1         1.000115    3647503.98        1.0   \n",
       "7                        1         0.999818   21261245.87        1.0   \n",
       "8                        1         0.999916    9473209.08        1.0   \n",
       "9                       -1         1.000969    6248958.45        1.0   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \n",
       "0         1.0   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704  \n",
       "1         1.0   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986  \n",
       "2         1.0   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950  \n",
       "3         1.0   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200  \n",
       "4         1.0   0.999394  16485.54   1.000016     434.10  1.0 -7.349849  \n",
       "5         1.0   0.999779   1962.72   1.000635    5647.65  1.0  6.779432  \n",
       "6         1.0   0.999506   6663.16   1.000283    3810.48  1.0 -2.499819  \n",
       "7         1.0   0.999741   5139.20   1.000130    2570.60  1.0 -1.959801  \n",
       "8         1.0   0.999022  52011.60   1.000041    2169.36  1.0 -5.970001  \n",
       "9         1.0   0.999354   6191.00   1.000646    6199.00  1.0  7.970333  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new dataframe with null values replaced by first mode\n",
    "train_df_mode = data_train.copy()\n",
    "\n",
    "# selecting first mode if more than one\n",
    "mode_values = train_df_mode.mode().iloc[0]\n",
    "train_df_mode.fillna(mode_values, inplace=True)\n",
    "train_df_mode.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f25b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking outliers in the data\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Boxplot to detect outlier in the train data\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "sns.boxplot(x=data_train['target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(dataframe, attribute):\n",
    "    # determine the number of rows containing outliers\n",
    "    # compute the 25th and 75th percentile value in target\n",
    "    percentile25 = dataframe[attribute].quantile(0.25)\n",
    "    percentile75 = dataframe[attribute].quantile(0.75)\n",
    "\n",
    "    # compute the interquatile range in target\n",
    "    iqr = percentile75 - percentile25\n",
    "\n",
    "    # define upper limit and lower limit for non-outlier values\n",
    "    upper_limit = percentile75 + (1.5 * iqr)\n",
    "    lower_limit = percentile25 - (1.5 * iqr)\n",
    "    print(\"Upper Limit:\", upper_limit)\n",
    "    print(\"Lower_Limit:\", lower_limit)\n",
    "\n",
    "    # identify the subset pf data containing outliers in target\n",
    "    outliers = dataframe[(dataframe[attribute] > upper_limit) | (dataframe[attribute] < lower_limit)]\n",
    "\n",
    "    # count how many rows in the data contain outliers in `target`\n",
    "    print(\"Number of rows in the data containing outliers in \", attribute, \":\", len(outliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For train_df_0: \n",
      "Upper Limit: 17.86351195\n",
      "Lower_Limit: -18.013715649999998\n",
      "Number of rows in the data containing outliers in  target : 292263\n",
      "\n",
      "For train_df_mean: \n",
      "Upper Limit: 17.86351195\n",
      "Lower_Limit: -18.013715649999998\n",
      "Number of rows in the data containing outliers in  target : 292263\n",
      "\n",
      "For train_df_mode: \n",
      "Upper Limit: 17.86351195\n",
      "Lower_Limit: -18.013715649999998\n",
      "Number of rows in the data containing outliers in  target : 292263\n"
     ]
    }
   ],
   "source": [
    "print('For train_df_0: ')\n",
    "find_outliers(train_df_0, \"target\")\n",
    "\n",
    "print('\\nFor train_df_mean: ')\n",
    "find_outliers(train_df_mean, \"target\")\n",
    "\n",
    "print('\\nFor train_df_mode: ')\n",
    "find_outliers(train_df_mode, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\avani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# handling outliers using log\n",
    "\n",
    "train_df_0_log = train_df_0.copy()\n",
    "train_df_0_log['target'] = np.log1p(pd.to_numeric(train_df_0_log['target'], errors='coerce'))\n",
    "\n",
    "# train_df_mean_log = train_df_mean.copy()\n",
    "# train_df_mean_log['target'] = np.log1p(pd.to_numeric(train_df_mean_log['target'], errors='coerce'))\n",
    "\n",
    "# train_df_mode_log = train_df_mode.copy()\n",
    "# train_df_mode_log['target'] = np.log1p(pd.to_numeric(train_df_mode_log['target'], errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a RobustScaler obj\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# handling outliers using robust scaling\n",
    "train_df_0_rob = train_df_0.copy()\n",
    "train_df_0_rob['target'] = scaler.fit_transform(train_df_0_rob['target'].values.reshape(-1, 1))\n",
    "\n",
    "# train_df_mean_rob = train_df_mean.copy()\n",
    "# train_df_mean_rob['target'] = scaler.fit_transform(train_df_mean_rob['target'].values.reshape(-1, 1))\n",
    "\n",
    "# train_df_mode_rob = train_df_mode.copy()\n",
    "# train_df_mode_rob['target'] = scaler.fit_transform(train_df_mode_rob['target'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting a seed value to ensure reproducibility across different runs\n",
    "seed = 69\n",
    "\n",
    "# creating a TimeSeriesSplit object with 10 splits. \n",
    "# TimeSeriesSplit is a cross-validator that provides train/test indices to split time series data.\n",
    "tss = TimeSeriesSplit(10)\n",
    "\n",
    "# setting the Python hash seed to the same value as the random seed\n",
    "# ensuring reproducibility when using hash-based operations in Python.\n",
    "os.environ['PYTHONHASHSEED'] = '69'\n",
    "\n",
    "# setting the random seed for TensorFlow's Keras API to ensure reproducibility in neural network training. \n",
    "tf.keras.utils.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_addition(x):\n",
    "    \"\"\"\n",
    "    Function to add various features to the input DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - x: Input DataFrame\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with additional features\n",
    "    \"\"\"\n",
    "    # list of initial features\n",
    "    list_of_features = ['seconds_in_bucket', 'imbalance_buy_sell_flag', 'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n",
    "                        'reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    # create a copy of the input DataFrame\n",
    "    x_copy = x.copy()\n",
    "    \n",
    "    # finding imbalance ratios\n",
    "    # measures the relative difference between the number of shares available for buying (bid) and selling (ask). \n",
    "    # it helps the model understand the balance between buyers and sellers in the order book.\n",
    "    x_copy['imb_s1'] = x.eval('(bid_size - ask_size) / (bid_size + ask_size)')\n",
    "\n",
    "    # captures the relative difference between the total unmatched shares and the shares that have found a match. \n",
    "    # this provides insights into the imbalance between supply and demand.\n",
    "    x_copy['imb_s2'] = x.eval('(imbalance_size - matched_size) / (matched_size + imbalance_size)')\n",
    "    \n",
    "    # list of price-related features\n",
    "    list_of_prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    # for each pair of prices the code calculates a ratio that expresses the imbalance between them. \n",
    "    # valuable for understanding how different price levels interact and influence each other.\n",
    "    for i, a in enumerate(list_of_prices):\n",
    "        for j, b in enumerate(list_of_prices):\n",
    "            if i > j:\n",
    "                # price differences as ratios\n",
    "                x_copy[f'{a}_{b}_imb'] = x.eval(f'({a} - {b}) / ({a} + {b})')\n",
    "                list_of_features.append(f'{a}_{b}_imb')\n",
    "\n",
    "    # takes into account sets of three prices and calculates a ratio based on their maximum, minimum, and middle values. \n",
    "    # introduces a more sophisticated understanding of the relationships between multiple price levels.\n",
    "    # in financial markets, understanding the dynamics between various price levels is crucial for predicting price movements and making informed trading decisions.               \n",
    "    for i, a in enumerate(list_of_prices):\n",
    "        for j, b in enumerate(list_of_prices):\n",
    "            for k, c in enumerate(list_of_prices):\n",
    "                if i > j and j > k:\n",
    "                    # triple-wise price differences as ratios\n",
    "                    max_ = x[[a, b, c]].max(axis=1)\n",
    "                    min_ = x[[a, b, c]].min(axis=1)\n",
    "                    mid_ = x[[a, b, c]].sum(axis=1) - min_ - max_\n",
    " \n",
    "                    x_copy[f'{a}_{b}_{c}_imb2'] = (max_ - mid_) / (mid_ - min_)\n",
    "                    list_of_features.append(f'{a}_{b}_{c}_imb2')\n",
    "                    \n",
    "    # additional Features\n",
    "    x_copy['spread'] = x['ask_price'] - x['bid_price']\n",
    "    x_copy['midpoint'] = 0.5 * (x['ask_price'] + x['bid_price'])\n",
    "    x_copy['price_range'] = x['far_price'] - x['near_price']\n",
    "    x_copy['wap_difference'] = x['wap'] - x['reference_price']\n",
    "    \n",
    "    # volatility Features\n",
    "    x_copy['price_volatility'] = x['wap'].pct_change().rolling(window=10).std()\n",
    "    x_copy['imbalance_volatility'] = x_copy['imbalance_size'].pct_change().rolling(window=10).std()\n",
    "    x_copy['ask_size_mean'] = x['ask_size'].rolling(window=10).mean()\n",
    "    x_copy['bid_size_mean'] = x['bid_size'].rolling(window=10).mean()\n",
    "\n",
    "    # appending the newly created features into the list\n",
    "    list_of_features.extend(['imb_s1', 'imb_s2', 'spread', 'midpoint', 'price_range', 'wap_difference', 'price_volatility', 'imbalance_volatility', 'ask_size_mean', 'bid_size_mean'])\n",
    " \n",
    "    return x_copy[list_of_features]\n",
    " \n",
    "FeatureAddition = FunctionTransformer(feature_addition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_impute(estimator, cv = tss, label = ''):\n",
    "    \n",
    "    X = data_train[~data_train.target.isna()].drop(['row_id', 'time_id'], axis = 1)\n",
    "    y = X.pop('target')\n",
    "    \n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    #train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating metrics\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        model = clone(estimator)\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        #append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    print('Imputed Train Dataframe')\n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_0(estimator, cv = tss, label = ''):\n",
    "    \n",
    "    X = train_df_0[~train_df_0.target.isna()]\n",
    "    y = X.pop('target')\n",
    "    \n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    #train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating metrics\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        model = clone(estimator)\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        #append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    print('Train Dataframe with NA replaced with 0')\n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_mean(estimator, cv = tss, label = ''):\n",
    "    \n",
    "    X = train_df_mean[~train_df_mean.target.isna()]\n",
    "    y = X.pop('target')\n",
    "    \n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    #train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating metrics\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        model = clone(estimator)\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        #append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    print('Train Dataframe with NA replaced with mean')\n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_mode(estimator, cv = tss, label = ''):\n",
    "    \n",
    "    X = train_df_mode[~train_df_mode.target.isna()]\n",
    "    y = X.pop('target')\n",
    "    \n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    #train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating metrics\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        model = clone(estimator)\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        #append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    print('Train Dataframe with NA replaced with mode')\n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 476180, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (23.61 MB) transferred to GPU in 0.036600 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 952360, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (47.23 MB) transferred to GPU in 0.091549 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.050068\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428540, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (70.84 MB) transferred to GPU in 0.322565 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.050068\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904720, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (94.46 MB) transferred to GPU in 0.141868 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 2380900, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (118.07 MB) transferred to GPU in 0.176491 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.079870\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 2857080, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (141.69 MB) transferred to GPU in 0.273544 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.069737\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 3333260, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (165.30 MB) transferred to GPU in 0.245239 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 3809440, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (188.91 MB) transferred to GPU in 0.309138 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4285620, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (212.53 MB) transferred to GPU in 0.346007 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.069737\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4761800, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (236.14 MB) transferred to GPU in 0.372523 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "Train Dataframe with NA replaced with 0\n",
      "Val Score: 6.38799 ± 0.50918 | Train Score: 6.11432 ± 0.41557 | LightGBM\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    # ('XGBoost', XGBRegressor(random_state = seed, objective = 'reg:absoluteerror', tree_method = 'gpu_hist', missing = np.nan)),\n",
    "    ('LightGBM', LGBMRegressor(random_state = seed, objective = 'mae', device_type = 'gpu')),\n",
    "    # ('CatBoost', CatBoostRegressor(random_state = seed, objective = 'MAE', verbose = 0))\n",
    "]\n",
    "\n",
    "for (label, model) in models:\n",
    "    ans = train_predict_0(\n",
    "        make_pipeline(\n",
    "            FeatureAddition,\n",
    "            model\n",
    "        ),\n",
    "        label = label\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_0_X = train_df_0[~train_df_0.target.isna()]\n",
    "train_df_0_Y = train_df_0_X.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 5237980, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (259.76 MB) transferred to GPU in 0.288197 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    FeatureAddition,\n",
    "    LGBMRegressor(random_state = seed, objective = 'mae', device_type = 'gpu',  n_estimators=250)\n",
    ")\n",
    "\n",
    "model.fit(train_df_0_X, train_df_0_Y)\n",
    "\n",
    "sample_prediction = pd.read_csv('sample_submission.csv')\n",
    "sample_prediction['target'] = model.predict(data_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prediction.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "revealed_data = pd.read_csv('revealed_targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revealed_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -2.310276\n",
       "1   -12.850165\n",
       "2    -0.439882\n",
       "3     7.259846\n",
       "4     4.780292\n",
       "Name: revealed_target, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revealed_data_target = revealed_data['revealed_target']\n",
    "revealed_data_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = sample_prediction['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqbal = pd.read_csv('C:/Users/avani/Downloads/submission.csv')\n",
    "iqbaltarget = iqbal['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5.49364\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(iqbaltarget, revealed_data_target)\n",
    "\n",
    "# Print MAE\n",
    "print(f'Mean Absolute Error: {mae:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5.81679\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(predicted_values, revealed_data_target)\n",
    "\n",
    "# Print MAE\n",
    "print(f'Mean Absolute Error: {mae:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.59933\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(iqbaltarget, predicted_values)\n",
    "\n",
    "# Print MAE\n",
    "print(f'Mean Absolute Error: {mae:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.909637888176167"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.5628\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(iqbaltarget, predicted_values)\n",
    "print(f'R-squared: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv').drop(['row_id', 'time_id'], axis=1)\n",
    "\n",
    "data.fillna(data.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'target' is your target variable column\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (80%), testing (10%), and validation (10%) sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 3.035871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 14083\n",
      "[LightGBM] [Info] Number of data points in the train set: 4190384, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score -0.060201\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function imbalance_calculator at 0x0000022B3B457700&gt;)),\n",
       "                (&#x27;lgbmregressor&#x27;,\n",
       "                 LGBMRegressor(n_estimators=500, objective=&#x27;mae&#x27;,\n",
       "                               random_state=69))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function imbalance_calculator at 0x0000022B3B457700&gt;)),\n",
       "                (&#x27;lgbmregressor&#x27;,\n",
       "                 LGBMRegressor(n_estimators=500, objective=&#x27;mae&#x27;,\n",
       "                               random_state=69))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function imbalance_calculator at 0x0000022B3B457700&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(n_estimators=500, objective=&#x27;mae&#x27;, random_state=69)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('functiontransformer',\n",
       "                 FunctionTransformer(func=<function imbalance_calculator at 0x0000022B3B457700>)),\n",
       "                ('lgbmregressor',\n",
       "                 LGBMRegressor(n_estimators=500, objective='mae',\n",
       "                               random_state=69))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = make_pipeline(\n",
    "    FeatureAddition,\n",
    "    LGBMRegressor(random_state = seed, objective = 'mae', n_estimators=500)\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE on Validation Set: 6.2461\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using Mean Absolute Error (MAE) on the validation set\n",
    "mae_val = mean_absolute_error(y_val, model.predict(X_val))\n",
    "\n",
    "print(f'MAE on Validation Set: {mae_val:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5237980, 15) (4190384, 14) (523798, 14) (523798, 14) (523798,)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, X_train.shape, X_test.shape, X_val.shape, y_test_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241.22"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.43255478622195"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.0688\n"
     ]
    }
   ],
   "source": [
    "r2 = r2_score(y_val, model.predict(X_val))\n",
    "print(f'R-squared: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\avani\\OneDrive\\Documents\\QuantumQube-Stock-Prediction\\Final_Project.ipynb Cell 69\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/avani/OneDrive/Documents/QuantumQube-Stock-Prediction/Final_Project.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y\u001b[39m.\u001b[39mmax()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
