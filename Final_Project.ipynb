{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91487f2d",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "415be5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "# For data maniplution\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# for data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# for confusion Matrix and Train_test\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error, classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import *\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import logging\n",
    "# Set LightGBM logging level to suppress info logs\n",
    "lgb_logger = logging.getLogger('lightgbm')\n",
    "lgb_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d9bfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset to dataframe\n",
    "data_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('test.csv').drop(['row_id', 'time_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying the first 10 rows\n",
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3936ea00",
   "metadata": {},
   "source": [
    "###Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting information about the train data\n",
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1bd4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting descriptive statistics about the train data\n",
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce5905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the data: number of rows and columns\n",
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b4edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "data_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the heatmap for the train dataset\n",
    "plt.figure(figsize=(16,16))\n",
    "sns.heatmap(data_train.corr(),annot=True,cmap='crest')\n",
    "plt.title('Heatmap of the tain dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the time series data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data_train['target'], label='Target')\n",
    "plt.title('Time Series Data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping all the null values and assigning it to a new dataframe\n",
    "data_train_wo_na = data_train.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if there is still any null data present\n",
    "data_train_wo_na.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is one more method to deal with the missing values for all the columns with simpleImputer.\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Save the original data types\n",
    "original_dtypes = data_train.dtypes\n",
    "\n",
    "# Create a SimpleImputer instance\n",
    "imp_mean = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Fit and transform the imputer on the original DataFrame\n",
    "imputed_train_array = imp_mean.fit_transform(data_train)\n",
    "\n",
    "# Convert the NumPy array back to a DataFrame\n",
    "imputed_train_df = pd.DataFrame(imputed_train_array, columns=data_train.columns)\n",
    "\n",
    "# Convert columns back to their original data types\n",
    "imputed_train_df = imputed_train_df.astype(original_dtypes)\n",
    "\n",
    "# Now, 'imputed_train_df' is your DataFrame with missing values imputed\n",
    "# imputed_train_df.head(20)\n",
    "imputed_train_df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>13552875.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>1962.72</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>5647.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.779432</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969969.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000115</td>\n",
       "      <td>3647503.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>6663.16</td>\n",
       "      <td>1.000283</td>\n",
       "      <td>3810.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.499819</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9412959.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>21261245.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>5139.20</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>2570.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.959801</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2394875.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>9473209.08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>52011.60</td>\n",
       "      <td>1.000041</td>\n",
       "      <td>2169.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.970001</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3039700.65</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000969</td>\n",
       "      <td>6248958.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>6191.00</td>\n",
       "      <td>1.000646</td>\n",
       "      <td>6199.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.970333</td>\n",
       "      <td>0</td>\n",
       "      <td>0_0_9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "5         5        0                  0            0.00   \n",
       "6         6        0                  0       969969.40   \n",
       "7         7        0                  0      9412959.10   \n",
       "8         8        0                  0      2394875.85   \n",
       "9         9        0                  0      3039700.65   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        0.0   \n",
       "1                       -1         0.999896    1642214.25        0.0   \n",
       "2                       -1         0.999561    1819368.03        0.0   \n",
       "3                       -1         1.000171   18389745.62        0.0   \n",
       "4                       -1         0.999532   17860614.95        0.0   \n",
       "5                        0         1.000635   13552875.92        0.0   \n",
       "6                        1         1.000115    3647503.98        0.0   \n",
       "7                        1         0.999818   21261245.87        0.0   \n",
       "8                        1         0.999916    9473209.08        0.0   \n",
       "9                       -1         1.000969    6248958.45        0.0   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \\\n",
       "0         0.0   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704   \n",
       "1         0.0   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986   \n",
       "2         0.0   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950   \n",
       "3         0.0   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200   \n",
       "4         0.0   0.999394  16485.54   1.000016     434.10  1.0 -7.349849   \n",
       "5         0.0   0.999779   1962.72   1.000635    5647.65  1.0  6.779432   \n",
       "6         0.0   0.999506   6663.16   1.000283    3810.48  1.0 -2.499819   \n",
       "7         0.0   0.999741   5139.20   1.000130    2570.60  1.0 -1.959801   \n",
       "8         0.0   0.999022  52011.60   1.000041    2169.36  1.0 -5.970001   \n",
       "9         0.0   0.999354   6191.00   1.000646    6199.00  1.0  7.970333   \n",
       "\n",
       "   time_id row_id  \n",
       "0        0  0_0_0  \n",
       "1        0  0_0_1  \n",
       "2        0  0_0_2  \n",
       "3        0  0_0_3  \n",
       "4        0  0_0_4  \n",
       "5        0  0_0_5  \n",
       "6        0  0_0_6  \n",
       "7        0  0_0_7  \n",
       "8        0  0_0_8  \n",
       "9        0  0_0_9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_0 = data_train.copy()\n",
    "train_df_0.fillna(0, inplace=True)\n",
    "train_df_0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>13552875.92</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>1962.72</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>5647.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.779432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969969.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000115</td>\n",
       "      <td>3647503.98</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>6663.16</td>\n",
       "      <td>1.000283</td>\n",
       "      <td>3810.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.499819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9412959.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>21261245.87</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>5139.20</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>2570.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.959801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2394875.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>9473209.08</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>52011.60</td>\n",
       "      <td>1.000041</td>\n",
       "      <td>2169.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3039700.65</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000969</td>\n",
       "      <td>6248958.45</td>\n",
       "      <td>1.001713</td>\n",
       "      <td>0.99966</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>6191.00</td>\n",
       "      <td>1.000646</td>\n",
       "      <td>6199.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.970333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "5         5        0                  0            0.00   \n",
       "6         6        0                  0       969969.40   \n",
       "7         7        0                  0      9412959.10   \n",
       "8         8        0                  0      2394875.85   \n",
       "9         9        0                  0      3039700.65   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64   1.001713   \n",
       "1                       -1         0.999896    1642214.25   1.001713   \n",
       "2                       -1         0.999561    1819368.03   1.001713   \n",
       "3                       -1         1.000171   18389745.62   1.001713   \n",
       "4                       -1         0.999532   17860614.95   1.001713   \n",
       "5                        0         1.000635   13552875.92   1.001713   \n",
       "6                        1         1.000115    3647503.98   1.001713   \n",
       "7                        1         0.999818   21261245.87   1.001713   \n",
       "8                        1         0.999916    9473209.08   1.001713   \n",
       "9                       -1         1.000969    6248958.45   1.001713   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \n",
       "0     0.99966   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704  \n",
       "1     0.99966   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986  \n",
       "2     0.99966   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950  \n",
       "3     0.99966   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200  \n",
       "4     0.99966   0.999394  16485.54   1.000016     434.10  1.0 -7.349849  \n",
       "5     0.99966   0.999779   1962.72   1.000635    5647.65  1.0  6.779432  \n",
       "6     0.99966   0.999506   6663.16   1.000283    3810.48  1.0 -2.499819  \n",
       "7     0.99966   0.999741   5139.20   1.000130    2570.60  1.0 -1.959801  \n",
       "8     0.99966   0.999022  52011.60   1.000041    2169.36  1.0 -5.970001  \n",
       "9     0.99966   0.999354   6191.00   1.000646    6199.00  1.0  7.970333  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_mean = data_train.copy()\n",
    "train_df_mean = train_df_mean.drop(['row_id', 'time_id'], axis = 1)\n",
    "train_df_mean.fillna(train_df_mean.mean(), inplace=True)\n",
    "train_df_mean.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>date_id</th>\n",
       "      <th>seconds_in_bucket</th>\n",
       "      <th>imbalance_size</th>\n",
       "      <th>imbalance_buy_sell_flag</th>\n",
       "      <th>reference_price</th>\n",
       "      <th>matched_size</th>\n",
       "      <th>far_price</th>\n",
       "      <th>near_price</th>\n",
       "      <th>bid_price</th>\n",
       "      <th>bid_size</th>\n",
       "      <th>ask_price</th>\n",
       "      <th>ask_size</th>\n",
       "      <th>wap</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3180602.69</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>13380276.64</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999812</td>\n",
       "      <td>60651.50</td>\n",
       "      <td>1.000026</td>\n",
       "      <td>8493.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.029704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166603.91</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>1642214.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999896</td>\n",
       "      <td>3233.04</td>\n",
       "      <td>1.000660</td>\n",
       "      <td>20605.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.519986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>302879.87</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999561</td>\n",
       "      <td>1819368.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999403</td>\n",
       "      <td>37956.00</td>\n",
       "      <td>1.000298</td>\n",
       "      <td>18995.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-8.389950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11917682.27</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000171</td>\n",
       "      <td>18389745.62</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>2324.90</td>\n",
       "      <td>1.000214</td>\n",
       "      <td>479032.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>447549.96</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.999532</td>\n",
       "      <td>17860614.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999394</td>\n",
       "      <td>16485.54</td>\n",
       "      <td>1.000016</td>\n",
       "      <td>434.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.349849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>13552875.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999779</td>\n",
       "      <td>1962.72</td>\n",
       "      <td>1.000635</td>\n",
       "      <td>5647.65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.779432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969969.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000115</td>\n",
       "      <td>3647503.98</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999506</td>\n",
       "      <td>6663.16</td>\n",
       "      <td>1.000283</td>\n",
       "      <td>3810.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.499819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9412959.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999818</td>\n",
       "      <td>21261245.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999741</td>\n",
       "      <td>5139.20</td>\n",
       "      <td>1.000130</td>\n",
       "      <td>2570.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.959801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2394875.85</td>\n",
       "      <td>1</td>\n",
       "      <td>0.999916</td>\n",
       "      <td>9473209.08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>52011.60</td>\n",
       "      <td>1.000041</td>\n",
       "      <td>2169.36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3039700.65</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.000969</td>\n",
       "      <td>6248958.45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999354</td>\n",
       "      <td>6191.00</td>\n",
       "      <td>1.000646</td>\n",
       "      <td>6199.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.970333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  date_id  seconds_in_bucket  imbalance_size  \\\n",
       "0         0        0                  0      3180602.69   \n",
       "1         1        0                  0       166603.91   \n",
       "2         2        0                  0       302879.87   \n",
       "3         3        0                  0     11917682.27   \n",
       "4         4        0                  0       447549.96   \n",
       "5         5        0                  0            0.00   \n",
       "6         6        0                  0       969969.40   \n",
       "7         7        0                  0      9412959.10   \n",
       "8         8        0                  0      2394875.85   \n",
       "9         9        0                  0      3039700.65   \n",
       "\n",
       "   imbalance_buy_sell_flag  reference_price  matched_size  far_price  \\\n",
       "0                        1         0.999812   13380276.64        1.0   \n",
       "1                       -1         0.999896    1642214.25        1.0   \n",
       "2                       -1         0.999561    1819368.03        1.0   \n",
       "3                       -1         1.000171   18389745.62        1.0   \n",
       "4                       -1         0.999532   17860614.95        1.0   \n",
       "5                        0         1.000635   13552875.92        1.0   \n",
       "6                        1         1.000115    3647503.98        1.0   \n",
       "7                        1         0.999818   21261245.87        1.0   \n",
       "8                        1         0.999916    9473209.08        1.0   \n",
       "9                       -1         1.000969    6248958.45        1.0   \n",
       "\n",
       "   near_price  bid_price  bid_size  ask_price   ask_size  wap    target  \n",
       "0         1.0   0.999812  60651.50   1.000026    8493.03  1.0 -3.029704  \n",
       "1         1.0   0.999896   3233.04   1.000660   20605.09  1.0 -5.519986  \n",
       "2         1.0   0.999403  37956.00   1.000298   18995.00  1.0 -8.389950  \n",
       "3         1.0   0.999999   2324.90   1.000214  479032.40  1.0 -4.010200  \n",
       "4         1.0   0.999394  16485.54   1.000016     434.10  1.0 -7.349849  \n",
       "5         1.0   0.999779   1962.72   1.000635    5647.65  1.0  6.779432  \n",
       "6         1.0   0.999506   6663.16   1.000283    3810.48  1.0 -2.499819  \n",
       "7         1.0   0.999741   5139.20   1.000130    2570.60  1.0 -1.959801  \n",
       "8         1.0   0.999022  52011.60   1.000041    2169.36  1.0 -5.970001  \n",
       "9         1.0   0.999354   6191.00   1.000646    6199.00  1.0  7.970333  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_mode = data_train.copy()\n",
    "train_df_mode = train_df_mode.drop(['row_id', 'time_id'], axis = 1)\n",
    "mode_values = train_df_mode.mode().iloc[0]\n",
    "train_df_mode.fillna(mode_values, inplace=True)\n",
    "train_df_mode.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_train_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f25b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking outliers in the data\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title(\"Boxplot to detect outlier in the train data\", fontsize=14)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "sns.boxplot(x=imputed_train_df['target'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(dataframe, attribute):\n",
    "    #Determine the number of rows containing outliers\n",
    "    # compute the 25th percentile value in target\n",
    "    percentile25 = dataframe[attribute].quantile(0.25)\n",
    "\n",
    "    # compute the 75th percentile value in target\n",
    "    percentile75 = dataframe[attribute].quantile(0.75)\n",
    "\n",
    "    #compute the interquatile range in target\n",
    "    iqr = percentile75 - percentile25\n",
    "\n",
    "    #define upper limit and lower limit for non-outlier values\n",
    "    upper_limit = percentile75 + (1.5 * iqr)\n",
    "    lower_limit = percentile25 - (1.5 * iqr)\n",
    "    print(\"Upper Limit:\", upper_limit)\n",
    "    print(\"Lower_Limit:\", lower_limit)\n",
    "\n",
    "    #identify the subset pf data containing outliers in target\n",
    "    outliers = dataframe[(dataframe[attribute] > upper_limit) | (dataframe[attribute] < lower_limit)]\n",
    "\n",
    "    # Count how many rows in the data contain outliers in `target`\n",
    "    print(\"Number of rows in the data containing outliers in \", attribute, \":\", len(outliers))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_outliers(imputed_train_df, \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_outliers(imputed_train_df, 'wap')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Log transformation\n",
    "imputed_log_train_df = imputed_train_df.copy()\n",
    "imputed_log_train_df['target'] = np.log1p(pd.to_numeric(imputed_log_train_df['target'], errors='coerce'))\n",
    "# data_train['target']= np.log1p(data_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\avani\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_df_0_log = train_df_0.copy()\n",
    "train_df_0_log['target'] = np.log1p(pd.to_numeric(train_df_0_log['target'], errors='coerce'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Apply robust scaling\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_rob_train_df = imputed_train_df.copy()\n",
    "imputed_rob_train_df['target']= scaler.fit_transform(imputed_rob_train_df['target'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_0_rob = train_df_0.copy()\n",
    "train_df_0_rob['target']= scaler.fit_transform(train_df_0_rob['target'].values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_outliers(imputed_log_train_df, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_outliers(imputed_rob_train_df, 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_rob_train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_log_train_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_train['imbalance_buy_sell_flag'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5610ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_train_df = imputed_train_df.drop(['row_id', 'time_id'], axis = 1)\n",
    "imputed_log_train_df = imputed_log_train_df.drop(['row_id', 'time_id'], axis = 1)\n",
    "imputed_rob_train_df = imputed_rob_train_df.drop(['row_id', 'time_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_0 = train_df_0.drop(['row_id', 'time_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed_train_df_X = imputed_train_df[~imputed_train_df.target.isna()]\n",
    "# imputed_train_df_Y = imputed_train_df_X.pop('target')\n",
    "\n",
    "# imputed_log_train_df_X = imputed_log_train_df[~imputed_log_train_df.target.isna()]\n",
    "# imputed_log_train_df_Y = imputed_log_train_df_X.pop('target')\n",
    "\n",
    "# imputed_rob_train_df_X = imputed_rob_train_df[~imputed_rob_train_df.target.isna()]\n",
    "# imputed_rob_train_df_Y = imputed_rob_train_df_X.pop('target')\n",
    "\n",
    "seed = 69\n",
    "tss = TimeSeriesSplit(10)\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '69'\n",
    "tf.keras.utils.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_0_X = train_df_0[~train_df_0.target.isna()]\n",
    "train_df_0_Y = train_df_0_X.pop('target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imbalance_calculator(x):\n",
    "    \n",
    "    list_of_features = ['seconds_in_bucket', 'imbalance_buy_sell_flag', 'imbalance_size', 'matched_size', 'bid_size', 'ask_size',\n",
    "                'reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap', 'imb_s1', 'imb_s2']\n",
    "    \n",
    "    x_copy = x.copy()\n",
    "    \n",
    "    x_copy['imb_s1'] = x.eval('(bid_size - ask_size) / (bid_size + ask_size)')\n",
    "    x_copy['imb_s2'] = x.eval('(imbalance_size - matched_size) / (matched_size + imbalance_size)')\n",
    "    \n",
    "    list_of_prices = ['reference_price','far_price', 'near_price', 'ask_price', 'bid_price', 'wap']\n",
    "    \n",
    "    for i,a in enumerate(list_of_prices):\n",
    "        for j,b in enumerate(list_of_prices):\n",
    "            if i>j:\n",
    "                x_copy[f'{a}_{b}_imb'] = x.eval(f'({a} - {b}) / ({a} + {b})')\n",
    "                list_of_features.append(f'{a}_{b}_imb')\n",
    "                    \n",
    "    for i,a in enumerate(list_of_prices):\n",
    "        for j,b in enumerate(list_of_prices):\n",
    "            for k,c in enumerate(list_of_prices):\n",
    "                if i>j and j>k:\n",
    "                    max_ = x[[a,b,c]].max(axis=1)\n",
    "                    min_ = x[[a,b,c]].min(axis=1)\n",
    "                    mid_ = x[[a,b,c]].sum(axis=1)-min_-max_\n",
    "\n",
    "                    x_copy[f'{a}_{b}_{c}_imb2'] = (max_-mid_)/(mid_-min_)\n",
    "                    list_of_features.append(f'{a}_{b}_{c}_imb2')\n",
    "    \n",
    "    return x_copy[list_of_features]\n",
    "\n",
    "ImbalanceCalculator = FunctionTransformer(imbalance_calculator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_impute(estimator, cv = tss, label = ''):\n",
    "    \n",
    "    X = data_train[~data_train.target.isna()].drop(['row_id', 'time_id'], axis = 1)\n",
    "    y = X.pop('target')\n",
    "    \n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    #train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating metrics\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        model = clone(estimator)\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        #append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    print('Imputed Train Dataframe')\n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_0(estimator, cv = tss, label = ''):\n",
    "    \n",
    "    X = train_df_0[~train_df_0.target.isna()]\n",
    "    y = X.pop('target')\n",
    "    \n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    #train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating metrics\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        model = clone(estimator)\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        #append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    print('Train Dataframe with NA replaced with 0')\n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_mean(estimator, cv = tss, label = ''):\n",
    "    \n",
    "    X = train_df_mean[~train_df_mean.target.isna()]\n",
    "    y = X.pop('target')\n",
    "    \n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    #train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating metrics\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        model = clone(estimator)\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        #append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    print('Train Dataframe with NA replaced with mean')\n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict_mode(estimator, cv = tss, label = ''):\n",
    "    \n",
    "    X = train_df_mode[~train_df_mode.target.isna()]\n",
    "    y = X.pop('target')\n",
    "    \n",
    "    #initiate prediction arrays and score lists\n",
    "    val_predictions = np.zeros((len(X)))\n",
    "    #train_predictions = np.zeros((len(sample)))\n",
    "    train_scores, val_scores = [], []\n",
    "    \n",
    "    #training model, predicting prognosis probability, and evaluating metrics\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        \n",
    "        model = clone(estimator)\n",
    "        \n",
    "        #define train set\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y.iloc[train_idx]\n",
    "        \n",
    "        #define validation set\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y.iloc[val_idx]\n",
    "        \n",
    "        #train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #make predictions\n",
    "        train_preds = model.predict(X_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "                  \n",
    "        val_predictions[val_idx] += val_preds\n",
    "        \n",
    "        #evaluate model for a fold\n",
    "        train_score = mean_absolute_error(y_train, train_preds)\n",
    "        val_score = mean_absolute_error(y_val, val_preds)\n",
    "        \n",
    "        #append model score for a fold to list\n",
    "        train_scores.append(train_score)\n",
    "        val_scores.append(val_score)\n",
    "    print('Train Dataframe with NA replaced with mode')\n",
    "    print(f'Val Score: {np.mean(val_scores):.5f} ± {np.std(val_scores):.5f} | Train Score: {np.mean(train_scores):.5f} ± {np.std(train_scores):.5f} | {label}')\n",
    "    \n",
    "    return val_scores, val_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 476180, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (23.61 MB) transferred to GPU in 0.036600 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 952360, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (47.23 MB) transferred to GPU in 0.091549 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.050068\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 1428540, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (70.84 MB) transferred to GPU in 0.322565 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.050068\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 1904720, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (94.46 MB) transferred to GPU in 0.141868 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 2380900, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (118.07 MB) transferred to GPU in 0.176491 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.079870\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 2857080, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (141.69 MB) transferred to GPU in 0.273544 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.069737\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 3333260, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (165.30 MB) transferred to GPU in 0.245239 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 3809440, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (188.91 MB) transferred to GPU in 0.309138 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4285620, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (212.53 MB) transferred to GPU in 0.346007 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.069737\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 4761800, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (236.14 MB) transferred to GPU in 0.372523 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n",
      "Train Dataframe with NA replaced with 0\n",
      "Val Score: 6.38799 ± 0.50918 | Train Score: 6.11432 ± 0.41557 | LightGBM\n"
     ]
    }
   ],
   "source": [
    "models = [\n",
    "    # ('XGBoost', XGBRegressor(random_state = seed, objective = 'reg:absoluteerror', tree_method = 'gpu_hist', missing = np.nan)),\n",
    "    ('LightGBM', LGBMRegressor(random_state = seed, objective = 'mae', device_type = 'gpu')),\n",
    "    # ('CatBoost', CatBoostRegressor(random_state = seed, objective = 'MAE', verbose = 0))\n",
    "]\n",
    "\n",
    "for (label, model) in models:\n",
    "    ans = train_predict_0(\n",
    "        make_pipeline(\n",
    "            ImbalanceCalculator,\n",
    "            model\n",
    "        ),\n",
    "        label = label\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 12043\n",
      "[LightGBM] [Info] Number of data points in the train set: 5237980, number of used features: 49\n",
      "[LightGBM] [Info] Using GPU Device: Intel(R) UHD Graphics, Vendor: Intel(R) Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 49 dense feature groups (259.76 MB) transferred to GPU in 0.392861 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score -0.060201\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = make_pipeline(\n",
    "    ImbalanceCalculator,\n",
    "    LGBMRegressor(random_state = seed, objective = 'mae', device_type = 'gpu', n_estimators=500)\n",
    ")\n",
    "\n",
    "model.fit(train_df_0_X, train_df_0_Y)\n",
    "\n",
    "sample_prediction = pd.read_csv('sample_submission.csv')\n",
    "sample_prediction['target'] = model.predict(data_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       time_id       row_id    target\n",
      "0        26290      478_0_0 -1.026933\n",
      "1        26290      478_0_1  2.105765\n",
      "2        26290      478_0_2  2.651761\n",
      "3        26290      478_0_3 -1.230203\n",
      "4        26290      478_0_4 -1.264654\n",
      "...        ...          ...       ...\n",
      "32995    26454  480_540_195 -1.502805\n",
      "32996    26454  480_540_196 -1.918891\n",
      "32997    26454  480_540_197  0.124417\n",
      "32998    26454  480_540_198  1.337283\n",
      "32999    26454  480_540_199 -2.973901\n",
      "\n",
      "[33000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(sample_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_id    0\n",
       "row_id     0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prediction.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "revealed_data = pd.read_csv('revealed_targets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stock_id             0\n",
       "date_id              0\n",
       "seconds_in_bucket    0\n",
       "time_id              0\n",
       "revealed_target      0\n",
       "revealed_date_id     0\n",
       "revealed_time_id     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revealed_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -2.310276\n",
       "1   -12.850165\n",
       "2    -0.439882\n",
       "3     7.259846\n",
       "4     4.780292\n",
       "Name: revealed_target, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revealed_data_target = revealed_data['revealed_target']\n",
    "revealed_data_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = sample_prediction['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqbal = pd.read_csv('C:/Users/avani/Downloads/submission.csv')\n",
    "iqbaltarget = iqbal['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5.49364\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(iqbaltarget, revealed_data_target)\n",
    "\n",
    "# Print MAE\n",
    "print(f'Mean Absolute Error: {mae:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 5.81679\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(revealed_data_target, predicted_values)\n",
    "\n",
    "# Print MAE\n",
    "print(f'Mean Absolute Error: {mae:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.77453\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(iqbaltarget, predicted_values)\n",
    "\n",
    "# Print MAE\n",
    "print(f'Mean Absolute Error: {mae:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
